# Paying Attention

## Introduction
*Paying Attention* is an attention-based explainer framework for graph transformers, taking inspiration from attention-based explainers for traditional NLP transformers using global, multihead attention mechanisms.

#
we neeed to train GraphGPS on syn1
create a function to do a trained model